<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="ai_demo">
  <title>Content Agent</title>
   <shortdesc>Content Agent can be used to classify input text and determine whether the text is polite. 
   </shortdesc>
  <prolog>
    <metadata>
      <keywords>
        <indexterm>AI</indexterm>
      </keywords>
    </metadata>
  </prolog>
  <conbody>
<p>Intel released an NLP library called Polite Guard that is able to classifiy and score text.   Content Agent is going to use its own reasoning with the additional help from Polite Guard to determine whether or not
content is polite.   
</p>

<p>Try out the demo at <xref href="https://huggingface.co/spaces/yetessam/ContentClassifier" type="html" scope="external">https://huggingface.co/spaces/yetessam/ContentClassifier</xref>.
 Submit text to the chat agent and see how it evaluates the content. 
</p>

<p>
<fig>
<title>Content Classifier Agent</title>
<desc>Written in Python and hosted on Hugging Face Spaces. Try out the demo at <xref href="https://huggingface.co/spaces/yetessam/ContentClassifier" type="html" scope="external">https://huggingface.co/spaces/yetessam/ContentClassifier</xref>. As part of your chat, submit text to the chat agent and see how it evaluates the content.
</desc>
 <image href="../../images/content_classifie.png" placement="break">
   <alt>Content Classifier App</alt>
</image>
</fig>
</p>  

<p>Generative AI is pre-trained to process language and avoid harmful interactions.   The content on which the AI is trained is not particularly transparent.  One way to provide greater accuracy, accountability, and transparency is to configure the Agent to call a specific toolset and connect specific libraries to AI Agents.
AI agents can be provided with any number of tools to assist in decision making. 
In this chat app, Polite Guard is added as a tool. </p>

<p>
Content Agent was provided with access to the <xref href="https://huggingface.co/Intel/polite-guard" type="html" scope="external">Polite Guard</xref> NLP library that classifies text and then was provided with sample functions to teach it how to make the function calls. Additionally, the agent has been instructed to use a structured process of setting up a task, thinking about the problem, running code using this tool, and making observations before providing an answer to the user.
Having the AI agent call a tool, rather than determine on its own whether content is acceptable, also means that it is simpler to add new features or upgrade through modifying the tooling.
Feeding AI Agent with specific tools and component libraries might take a bit more work at the start of a project, but is far more open and transparent. 
</p>
<p>Using saved prompts, the AI is provided with examples on when it should make direct function calls to Polite Guard.   
Then when the AI encounters content, it should call the function to get back back a label and score.  
Content AI is then supposed to take into account whether Polite Guard has labelled the as polite, somewhat polite, neutral, or impolite. 
</p>


<p>Continued work is needed to ensure the agent  “listens” to the polite_guard tool and adjust its classification accordingly.    Content should be evaluated based on the quantitative score provided by Polite Guard rather than the model's own assessments. Even where the AI does take the Polite Guard scoring into account, the AI agent is still introducing its own perspective and decisions making into the process. As <xref href="prompt-examples.dita#prompts/content-agent" type="concept" format="dita">prompting</xref> instructs it to improve text, all of those language suggestions are 100% coming from the model, not from the classification tool.
</p>

<p>The Python code is available in the Files section. It sets up a Gradio user interface, calls in the existing model, sets up prompts and passes the code agent the tool. See <xref href="https://huggingface.co/agents-course">Agents Course</xref> to learn how to create your first AI Agent.</p>
<note>Determining whether or not content is polite is a highly subjective and culturally biased task.  
All tools do and will continue to mislabel problematic content as "polite".   Opinions of marginalized groups, audience, language, culture, power dynamics, and history are a few of the many determinators of whether content is respectful.
</note>
</conbody>
</concept>
